# HILT-LED Challenge Scenarios (continued)

d - LO is appropriate but activity doesn't provide enough structure

**CORRECT ANSWERS:** First three (No scaffolding, Vague instructions, No testing guidance)

**FEEDBACK:**

**If All Correct:**
"Excellent QA analysis! You identified the key issues: lack of scaffolding (one example → build complete form), vague success criteria ('make it accessible' without specifics), and no guidance on testing/verification. A strong microlesson would include: definition → guided example → practice with template → independent creation, plus clear criteria for accessibility and instructions for testing with screen readers. This is exactly the kind of fresh-eyes perspective that catches issues before they reach learners."

**If Partially Correct:**
"You're thinking like a QA reviewer, but there are more issues to catch. Look at: (1) Scaffolding - does the lesson build from simple to complex? (2) Clarity - do learners know exactly what 'accessible' means in concrete terms? (3) Verification - how will learners know if they succeeded? Apply the rubric criteria systematically."

**If Incorrect:**
"Not quite. The QA rubric reveals several issues: missing scaffolding between example and practice, vague instructions that don't define 'accessible' concretely, and no testing/verification guidance. Strong QA means checking each rubric criterion - alignment, scaffolding, clarity, accessibility, inclusive language - and catching gaps before learners encounter them."

---

### Challenge 4: Work-Based Problem Design

**Challenge ID:** `assessment-4`  
**Title:** Work-Based Problem Design  
**Difficulty:** 4  
**Concepts:** WBP format, real-world application, assessment rigor  
**Badge:** Assessment Architect (earned after completing all 4 Assessment challenges)

**SCENARIO:**

You're evaluating two different assessments for a digital marketing analytics course. Both claim to measure learners' ability to apply data analysis skills, but they take very different approaches.

**Assessment Option A:**
"Explain what conversion rate means and why it's important for digital marketing."

**Assessment Option B:**

**Work-Based Problem: E-Commerce Conversion Analysis**

**Scenario:**  
You're a digital marketing analyst at an online fitness equipment retailer. Your manager shares this data from last month's email campaign:

- 50,000 emails sent
- 12,500 emails opened (25% open rate)
- 2,500 clicked through to product pages (20% click rate of opens)  
- 250 completed purchases (10% conversion rate of clicks)

Your manager asks: "Our conversion rate from click to purchase is lower than industry average (15%). What's going wrong?"

**Your Task (Choose One):**

**Ticket 1:** Calculate the overall campaign conversion rate (purchases/emails sent) and compare to the click-to-purchase rate. Write a 1-paragraph analysis explaining which metric better represents campaign success and why.

**Ticket 2:** The manager wants to improve the 10% click-to-purchase rate. Propose 2 data-informed hypotheses for why visitors aren't converting, and suggest one A/B test to validate each hypothesis.

**Deliverable:** Your analysis and recommendations in a brief email format (150-200 words)

**QUESTION:**

Which assessment better measures applied knowledge using work-based problem criteria?

**OPTIONS:**

**A)** Assessment A - it tests foundational knowledge which must come before application

**B)** Assessment B - it requires learners to analyze real data, apply concepts in context, and make data-informed decisions like they would in a professional role

**C)** Both are equally valid - they just measure different learning levels

**CORRECT ANSWER:** B

**FEEDBACK:**

**If Correct (Option B):**
"Excellent evaluation! Assessment B is a true work-based problem with all the key elements: realistic scenario, authentic data, professional context, meaningful decision-making, and multiple solution paths. It requires learners to apply knowledge (calculate rates, compare metrics), analyze (identify problems), and create (propose hypotheses and tests) - not just recall definitions. This type of assessment measures transfer of learning to real-world contexts, which is the ultimate goal of professional training."

**If Incorrect (Option A or C):**
"Not quite. While Assessment A measures foundational knowledge (remember/understand), Assessment B measures applied knowledge in a realistic professional context. Work-based problems should mirror actual job tasks - analyzing real data, making decisions with constraints, communicating recommendations. Assessment B provides scenario, requirements, deliverable format, and decision-making opportunities. This distinction matters because we want to assess whether learners can *use* knowledge in context, not just recall it."

---

## IMPLEMENTATION NOTES

### Interaction Types Summary:
- **Multiple Choice:** 10 challenges (prompting-1, prompting-2, bias-1, scaffolding-2, assessment-1, assessment-2, assessment-4, and 3 others)
- **Multi-select:** 3 challenges (bias-2, bias-3, assessment-3)
- **Drag-and-drop:** 3 challenges (prompting-3, scaffolding-1, scaffolding-3)
- **Hierarchical sorting:** 1 challenge (scaffolding-4)
- **Comparison/analysis:** Multiple embedded in scenarios

### Concept Coverage Map:

**All 22 concepts covered:**
1. ✅ Learning objectives (prompting-1, assessment-1)
2. ✅ Bloom's Taxonomy (prompting-1, scaffolding-1, scaffolding-2)
3. ✅ Scaffolding (prompting-3, scaffolding-1, scaffolding-3, assessment-3)
4. ✅ Problem-based learning (prompting-4, assessment-4)
5. ✅ Work-based problems (prompting-4, assessment-4)
6. ✅ Exercise design (assessment-2)
7. ✅ Examples vs case studies (prompting-4)
8. ✅ AI prompting (prompting-2)
9. ✅ AI risks & vigilance (prompting-3, bias-4)
10. ✅ Microlessons (prompting-2, scaffolding-2)
11. ✅ Modules (scaffolding-3)
12. ✅ Competencies (scaffolding-4)
13. ✅ Modular adaptability (scaffolding-4)
14. ✅ Modularization workflow (scaffolding-3, scaffolding-4)
15. ✅ Build types (implied in multiple)
16. ✅ LX Design System (assessment-2)
17. ✅ GitHub modularization (scaffolding-3)
18. ✅ Competency mapping (scaffolding-4)
19. ✅ QA rubrics (assessment-3)
20. ✅ Learner-centered perspective (bias-1, bias-3, assessment-3)
21. ✅ Accessibility (bias-3, assessment-3)
22. ✅ Inclusive language (bias-1, bias-2, bias-3)

### Badge Summary (One Badge Per Path):
- Path 1 (Prompting & Refinement): **Prompt Whisperer** - Awarded after completing all 4 challenges
- Path 2 (Bias & Ethics): **Bias Buster** - Awarded after completing all 4 challenges
- Path 3 (Scaffolding & Sequencing): **Scaffold Master** - Awarded after completing all 4 challenges
- Path 4 (Assessment Quality): **Assessment Architect** - Awarded after completing all 4 challenges

---

**END OF SCENARIOS DOCUMENT**

Ready for implementation in Claude Code!