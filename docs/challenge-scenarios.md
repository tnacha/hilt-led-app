# HILT-LED Challenge Scenarios
## Complete Scenario Library for All 16 Challenges

This document contains the detailed scenarios, questions, options, correct answers, and feedback for all challenges across the four paths.

---

## PATH 1: PROMPTING & REFINEMENT

### Challenge 1: Crafting Effective Learning Objectives

**Challenge ID:** `prompting-1`  
**Title:** Crafting Effective Learning Objectives  
**Difficulty:** 1  
**Concepts:** Learning objectives, SMART criteria, Bloom's Taxonomy  
**Badge:** Prompt Whisperer (earned after completing all 4 Prompting challenges)

**SCENARIO:**

You're working with an AI assistant to develop learning content for a corporate training program on agile project management. The AI has generated the following learning objectives for Module 1:

> "Learners will understand agile methodologies. They will know about sprint planning. They will learn teamwork and collaboration skills."

Your instructional design lead has flagged these objectives as too vague to be useful for either learners or instructors.

**QUESTION:**

Which revision best transforms these into specific, measurable learning objectives aligned to Bloom's Taxonomy?

**OPTIONS:**

**A)** By the end of this module, learners will be able to:
- Create a sprint backlog using user story point estimation
- Facilitate a sprint planning meeting following the Scrum framework
- Evaluate team velocity data to forecast sprint capacity

**B)** By the end of this module, learners will:
- Understand the core principles of agile project management
- Know how to collaborate effectively in team settings
- Learn about sprint planning best practices

**C)** By the end of this module, learners will:
- Know agile methodologies
- Understand teamwork
- Learn sprint planning basics

**CORRECT ANSWER:** A

**FEEDBACK:**

**If Correct (Option A):**
"Excellent! These objectives are specific, measurable, and aligned to different Bloom's levels. 'Create' (synthesis), 'Facilitate' (application), and 'Evaluate' (analysis) are all action verbs that can be observed and assessed. Each objective describes exactly what the learner will DO, not just what they'll 'understand' or 'know.'"

**If Incorrect (Option B or C):**
"Not quite. The objectives you selected still use vague language like 'understand,' 'know,' and 'learn' - these aren't measurable actions. Strong learning objectives should use specific action verbs from Bloom's Taxonomy (create, analyze, apply, evaluate) and describe observable behaviors. Try again and look for objectives that tell you exactly what learners will be able to DO."

---

### Challenge 2: Prompt Engineering for Microlessons

**Challenge ID:** `prompting-2`  
**Title:** Prompt Engineering for Microlessons  
**Difficulty:** 2  
**Concepts:** AI prompting, microlesson structure, role definition  
**Badge:** Prompt Whisperer (earned after completing all 4 Prompting challenges)

**SCENARIO:**

You need to use an AI assistant to help you create a 20-minute microlesson on "Introduction to Git Version Control" for a university-level software development course. The microlesson must include one clear learning objective and one hands-on activity.

You know that effective AI prompts include role definition, context, learning principles, desired format, and tone.

**QUESTION:**

Which prompt is most likely to generate a well-structured, pedagogically sound microlesson?

**OPTIONS:**

**A)** "Create a Git lesson."

**B)** "You are an instructional designer specializing in technical education. Create a 20-minute microlesson on 'Introduction to Git Version Control' for undergraduate computer science students with no prior version control experience. The microlesson must include: (1) one measurable learning objective using Bloom's Taxonomy, (2) one hands-on activity where students practice the skill, (3) clear step-by-step instructions. Use an encouraging, beginner-friendly tone."

**C)** "Write a lesson about Git for beginners. Make it simple and include some practice exercises."

**CORRECT ANSWER:** B

**FEEDBACK:**

**If Correct (Option B):**
"Perfect! This prompt sets the AI up for success by defining its role (instructional designer), providing clear context (audience, prerequisites, time constraint), specifying learning principles (Bloom's, measurable objectives, hands-on practice), and requesting a specific format and tone. This structured approach helps the AI generate content that aligns with instructional design best practices."

**If Incorrect (Option A or C):**
"Not quite. Effective prompts need more than just the topic. They should define the AI's role, provide audience context, specify desired format and learning principles, and set the tone. Vague prompts like 'create a lesson' or 'make it simple' lead to generic output that requires extensive revision. Look for the prompt that gives the AI everything it needs to generate pedagogically sound content on the first try."

---

### Challenge 3: Scaffolding AI-Generated Content

**Challenge ID:** `prompting-3`  
**Title:** Scaffolding AI-Generated Content  
**Difficulty:** 3  
**Concepts:** Scaffolding, Bloom's progression, AI risks  
**Badge:** Prompt Whisperer (earned after completing all 4 Prompting challenges)

**SCENARIO:**

You asked an AI assistant to help you design a module on "Data Visualization Best Practices" for a corporate analytics team. The AI generated the following sequence of microlessons:

1. "Definition of Data Visualization"
2. "Create a Dashboard for Your Organization"

When you review the output, you realize there's no scaffolding - it jumps from basic definition directly to advanced creation without any middle steps.

**QUESTION:**

Drag the following microlesson topics into the correct order to create proper scaffolding from foundational understanding to independent creation:

**ITEMS TO ARRANGE:**

- Definition of Data Visualization
- Analyze Examples of Effective vs Ineffective Dashboards
- Apply Design Principles to a Sample Dataset (Guided Practice)
- Create a Dashboard for Your Organization (Independent Project)

**CORRECT ORDER:**

1. Definition of Data Visualization (Remember/Understand)
2. Analyze Examples of Effective vs Ineffective Dashboards (Analyze)
3. Apply Design Principles to a Sample Dataset (Apply)
4. Create a Dashboard for Your Organization (Create)

**FEEDBACK:**

**If Correct:**
"Excellent scaffolding! You've built a logical progression following Bloom's Taxonomy: starting with foundational understanding, moving to analysis of examples, providing guided practice, and finally allowing independent creation. This approach builds learner confidence and competence step by step, rather than overwhelming them with a complex task before they're ready."

**If Incorrect:**
"Not quite. Effective scaffolding follows Bloom's progression: Understand → Analyze → Apply → Create. Learners need to build foundational knowledge, see examples, practice with guidance, and then create independently. Starting with creation or skipping the middle steps leaves learners without the support they need to succeed. Try reordering to build from simple to complex."

---

### Challenge 4: Refining AI Case Studies

**Challenge ID:** `prompting-4`  
**Title:** Refining AI Case Studies  
**Difficulty:** 4  
**Concepts:** Examples vs case studies, PBL, credibility, work-based problems  
**Badge:** Prompt Whisperer (earned after completing all 4 Prompting challenges)

**SCENARIO:**

You're developing a UX design course and asked an AI to create a practice exercise on user flow design. The AI generated this:

**AI-Generated Exercise:**
"Create a user flow diagram. Make sure it shows all the steps a user takes. Submit your diagram."

You recognize this as weak problem-based learning - it's generic, lacks context, and doesn't connect to real-world application.

**QUESTION:**

Which revision transforms this into a strong work-based problem with proper scenario, requirements, and real-world relevance?

**OPTIONS:**

**A)** 
**Exercise: User Flow Design**

Draw a user flow diagram for any website or app. Include all steps from start to finish. Submit your work.

**B)** 
**Work-Based Problem: E-Commerce Checkout Flow**

**Scenario:** You're a UX designer at an online bookstore. The product team reports that 45% of users abandon their cart during checkout. Your task is to redesign the checkout user flow to reduce friction.

**Requirements:**
- Map the current checkout flow (login, shipping, payment, confirmation)
- Identify 2-3 friction points causing abandonment
- Design an improved flow that reduces steps or clarifies progression
- Annotate your flow diagram with your design rationale

**Deliverable:** Annotated user flow diagram (digital or hand-drawn)

**C)** 
**Exercise: User Flow Practice**

Think about your favorite website. Create a user flow showing how someone might complete a purchase or sign up for an account. Make it clear and logical.

**CORRECT ANSWER:** B

**FEEDBACK:**

**If Correct (Option B):**
"Outstanding! This work-based problem includes all the essential elements: a realistic scenario grounded in actual UX challenges (cart abandonment), specific requirements that guide learners without spoon-feeding answers, clear deliverables, and a real-world context that makes the learning transferable. The task requires analysis, application, and creation - not just rote execution."

**If Incorrect (Option A or C):**
"Not quite. Strong work-based problems need specific scenarios, clear requirements, and real-world context. Generic prompts like 'draw any user flow' or 'think about your favorite website' don't provide the constraints and context that make learning meaningful and transferable. Look for the option that gives learners a realistic professional challenge to solve, not just an exercise to complete."

---

## PATH 2: BIAS & ETHICS

### Challenge 1: Spotting Cultural Bias

**Challenge ID:** `bias-1`  
**Title:** Spotting Cultural Bias  
**Difficulty:** 1  
**Concepts:** Inclusive language, global relevance, representation  
**Badge:** Bias Buster (earned after completing all 4 Bias challenges)

**SCENARIO:**

You're reviewing an AI-generated case study for a global leadership development program. The case study reads:

> "Meet Sarah, a product manager at a Silicon Valley tech startup. She needs to decide whether to pivot her team's roadmap based on feedback from venture capital investors in San Francisco. Consider how Sarah should approach stakeholder communication, prioritize features based on market fit, and navigate the fast-paced startup culture common in the Bay Area."

The program will be delivered to leaders across North America, Europe, Asia, and Latin America.

**QUESTION:**

What type of bias is present in this case study?

**OPTIONS:**

**A)** Cultural/Geographic Bias - The case study assumes all learners relate to Silicon Valley startup culture and U.S. venture capital contexts, which may not be relevant or familiar to global audiences.

**B)** Grammar Bias - The case study has incorrect sentence structure and needs editing.

**C)** Gender Bias - The case study only features a female protagonist and should include male examples as well.

**CORRECT ANSWER:** A

**FEEDBACK:**

**If Correct (Option A):**
"Exactly right! This case study is culturally and geographically biased. It centers exclusively on Silicon Valley startup culture, U.S. venture capital dynamics, and Bay Area context - elements that may be unfamiliar or irrelevant to learners in other regions. For a global program, case studies should either use universally relatable contexts or provide diverse examples representing different industries, regions, and organizational types."

**If Incorrect (Option B or C):**
"Not quite. The issue isn't grammar or gender representation - it's that the case study assumes all learners operate in or relate to Silicon Valley tech culture. For global audiences, this narrow geographic and cultural framing creates barriers to relevance and engagement. Inclusive case studies should use contexts that are globally relevant or provide diverse examples across regions and industries."

---

### Challenge 2: Representation in Examples

**Challenge ID:** `bias-2`  
**Title:** Representation in Examples  
**Difficulty:** 2  
**Concepts:** Diversity, credible sources, inclusive design  
**Badge:** Bias Buster (earned after completing all 4 Bias challenges)

**SCENARIO:**

You're conducting a QA review of an AI-generated management training module. As you review the examples and case studies, you notice a pattern:

- Example 1: "John, a 28-year-old marketing director..."
- Example 2: "Mike, a senior operations manager..."
- Example 3: "David, a young executive leading a product team..."
- Example 4: "Tom, a department head managing remote teams..."

All example professionals are:
- Male
- Presented with traditionally Western/English names
- Described as young (20s-30s)
- Shown in office-based leadership roles
- Depicted without any mention of disability, caregiving responsibilities, or non-traditional career paths

**QUESTION:**

Which dimensions of diversity are missing from these examples? (Select all that apply)

**OPTIONS (Multi-select):**

- [ ] Gender diversity
- [ ] Age diversity (older professionals, mid-career, various experience levels)
- [ ] Cultural/ethnic diversity (names, backgrounds, contexts)
- [ ] Ability/disability representation
- [ ] Role diversity (individual contributors, various industries, non-traditional paths)

**CORRECT ANSWERS:** All of them (Gender, Age, Cultural/ethnic, Ability, Role diversity)

**FEEDBACK:**

**If All Correct:**
"Excellent eye for representation! You identified all the missing dimensions. Inclusive learning design requires examples that reflect the full diversity of the professional world - different genders, ages, cultural backgrounds, abilities, and career paths. When learners see themselves and their experiences represented, engagement and transfer of learning increase significantly."

**If Partially Correct:**
"You're on the right track, but you missed some dimensions of diversity. Look again at gender (all male), age (all young), names/cultural backgrounds (all traditionally Western), ability representation (none mentioned), and role types (all traditional leadership). Inclusive examples should span all these dimensions so all learners feel seen and valued."

**If Incorrect:**
"Not quite. This set of examples lacks diversity across multiple dimensions: gender, age, cultural background, ability, and role types. Strong instructional design includes examples representing the full spectrum of professional experiences. Review the examples again and consider who is missing from these scenarios."

---

### Challenge 3: AI Assumptions & Accessibility

**Challenge ID:** `bias-3`  
**Title:** AI Assumptions & Accessibility  
**Difficulty:** 3  
**Concepts:** Accessibility, learner-centered design, assumptions  
**Badge:** Bias Buster (earned after completing all 4 Bias challenges)

**SCENARIO:**

You asked an AI assistant to create a collaborative exercise for a hybrid (in-person + remote) professional development workshop on data storytelling. The AI generated this:

**Exercise: Data Visualization Peer Review**

"In your breakout groups of 4, each person will screen-share their dashboard on Zoom while the others provide live feedback. Use the annotation tools to mark areas for improvement directly on the shared screen. After 20 minutes, reconvene in the main room and each group will present their favorite dashboard using the room's projection system."

As you review this, you realize the AI has made several assumptions about technology access, learner abilities, and learning environment.

**QUESTION:**

What accessibility and assumption issues do you identify? (Select all that apply)

**OPTIONS (Multi-select):**

- [ ] Assumes all learners have Zoom access and familiarity with screen-sharing
- [ ] Assumes all learners can see visual annotations on screen (not accessible for visually impaired)
- [ ] Assumes stable internet connection for all remote participants
- [ ] Assumes all in-person participants can see projection screen clearly
- [ ] Provides no alternative for asynchronous participation

**CORRECT ANSWERS:** All of them

**FEEDBACK:**

**If All Correct:**
"Outstanding accessibility awareness! You identified all the problematic assumptions. This exercise excludes learners who: don't have specific tools (Zoom, stable internet), have visual impairments, are in different time zones, or face technology barriers. Inclusive exercise design should provide multiple modalities (visual, verbal, text-based), offer asynchronous alternatives, and avoid requiring specific proprietary tools."

**If Partially Correct:**
"You're thinking about accessibility, but there are more issues to consider. Review the exercise again for assumptions about: technology access (Zoom, internet), sensory abilities (seeing screens/annotations), physical abilities (viewing projections), and time/schedule flexibility (synchronous-only design). Inclusive design means considering all these dimensions."

**If Incorrect:**
"Not quite. This exercise makes multiple assumptions that create barriers for learners. Consider: required technology (Zoom), visual dependencies (screen annotations, projections), internet stability, and synchronous-only participation. Accessible exercise design should work across different tools, abilities, and participation modes."

---

### Challenge 4: Vigilance Against AI "Falling Asleep"

**Challenge ID:** `bias-4`  
**Title:** Vigilance Against AI "Falling Asleep"  
**Difficulty:** 4  
**Concepts:** AI risks, expert vigilance, QA perspective, fresh-eyes review  
**Badge:** Bias Buster (earned after completing all 4 Bias challenges)

**SCENARIO:**

You're QA-reviewing a microlesson on "CSS Flexbox Fundamentals" that an AI assistant helped a colleague create. At first glance, the content looks polished and professional. The learning objective is clear, the examples are well-formatted, and the activity includes step-by-step instructions.

However, you're aware that high-quality AI output can cause experts to "fall asleep at the wheel" - trusting the content without rigorous review. You decide to read closely with a learner's fresh eyes.

Here's an excerpt from the activity instructions:

**Activity: Build a Responsive Navigation Bar**

"Use CSS Flexbox to create a horizontal navigation bar. Set the container to `display: flex` and apply `justify-content: space-around` to evenly distribute the nav items. For responsive design, use a media query to switch to `flex-direction: column` at screen widths below 768px. Don't forget to set `align-items: stretch` so all items have equal height."

**QUESTION:**

You spot 3 subtle errors that a learner would struggle with. What are they?

**OPTIONS (Multi-select):**

- [ ] `justify-content: space-around` doesn't evenly distribute items - that's `space-evenly` (or `space-between` depending on desired effect)
- [ ] `align-items: stretch` is the default value, so "don't forget" implies it's required when it's actually redundant
- [ ] The media query breakpoint of 768px is presented as a rule, but responsive breakpoints should be content-driven, not device-specific
- [ ] The instruction doesn't specify whether to use `flexbox` or `grid` (both are valid layout tools)

**CORRECT ANSWERS:** First three (justify-content, align-items, breakpoint)

**FEEDBACK:**

**If All Correct:**
"Excellent vigilance! You caught the subtle inaccuracies that could confuse learners: `space-around` vs `space-evenly`, the unnecessary instruction about `align-items: stretch` (it's the default), and the oversimplification of responsive breakpoints. This is exactly why human review is critical - AI can generate confident-sounding content that contains technical errors or outdated practices. Your 'fresh learner eyes' caught what an expert might skim past."

**If Partially Correct:**
"Good eye, but there are more subtle issues to catch. Review the specific property values (`space-around` vs correct distribution method), the redundant instruction about default values, and the oversimplified approach to breakpoints. AI-generated content often sounds authoritative even when it's subtly wrong - that's why rigorous QA is essential."

**If Incorrect:**
"Not quite. This content contains several subtle technical errors that would confuse learners: incorrect property value for even distribution, unnecessary instruction about a default value, and oversimplified responsive design guidance. The polish of AI-generated content can make us trust it too quickly. Always review with a learner's fresh eyes and verify technical accuracy."

---

## PATH 3: SCAFFOLDING & SEQUENCING

### Challenge 1: Bloom's Taxonomy Basics

**Challenge ID:** `scaffolding-1`  
**Title:** Bloom's Taxonomy Basics  
**Difficulty:** 1  
**Concepts:** Bloom's levels, progression logic  
**Badge:** Scaffold Master (earned after completing all 4 Scaffolding challenges)

**SCENARIO:**

You're reviewing a microlesson on "Introduction to SQL Queries" and notice the activities jump from basic memorization directly to complex creation without any middle steps.

Current sequence:
1. **Remember**: Memorize SQL SELECT syntax
2. **Create**: Build a multi-table database query with JOIN statements

**QUESTION:**

Drag the following activities into the correct order to create a proper Bloom's Taxonomy progression:

**ITEMS TO ARRANGE:**

- Memorize SQL SELECT syntax
- Explain the difference between INNER JOIN and LEFT JOIN
- Write a basic SELECT query to retrieve data from one table
- Debug a broken SQL query and fix the errors
- Build a multi-table database query with JOIN statements

**CORRECT ORDER:**

1. Memorize SQL SELECT syntax (Remember)
2. Explain the difference between INNER JOIN and LEFT JOIN (Understand)
3. Write a basic SELECT query to retrieve data from one table (Apply)
4. Debug a broken SQL query and fix the errors (Analyze)
5. Build a multi-table database query with JOIN statements (Create)

**FEEDBACK:**

**If Correct:**
"Perfect scaffolding! You've built a logical Bloom's progression: Remember → Understand → Apply → Analyze → Create. Each step builds on the previous one, giving learners the foundation they need before moving to more complex tasks. This prevents cognitive overload and builds confidence as they progress."

**If Incorrect:**
"Not quite. Bloom's Taxonomy follows a specific hierarchy: Remember (recall facts) → Understand (explain concepts) → Apply (use in simple contexts) → Analyze (break down, compare, debug) → Create (build something new). Jumping steps leaves learners without the foundational skills they need. Try reordering to build from simple to complex."

---

### Challenge 2: Microlesson Sequencing

**Challenge ID:** `scaffolding-2`  
**Title:** Microlesson Sequencing  
**Difficulty:** 2  
**Concepts:** Microlesson structure, activity alignment to LO  
**Badge:** Scaffold Master (earned after completing all 4 Scaffolding challenges)

**SCENARIO:**

You're building a microlesson on "Conducting User Interviews" for a UX research course. You have a learning objective and several possible activities, but they need to align properly.

**Learning Objective:**
"Learners will be able to conduct a semi-structured user interview using open-ended questions and active listening techniques."

**QUESTION:**

Which activity best aligns with this learning objective for a 20-minute microlesson?

**OPTIONS:**

**A)** Watch a 15-minute video lecture on the history of user research methodologies, then complete a multiple-choice quiz on key terms.

**B)** Read a case study about a successful user interview project, then write a reflection on what made it effective.

**C)** Review a list of open-ended vs closed-ended question examples, then practice conducting a 10-minute mock user interview with a partner using a provided script template.

**CORRECT ANSWER:** C

**FEEDBACK:**

**If Correct (Option C):**
"Excellent alignment! The learning objective requires learners to 'conduct' an interview (application level), so the activity must give them hands-on practice. Option C provides scaffolding (examples of question types), then guided practice (mock interview with template), directly addressing the LO. This is what a well-structured microlesson looks like: one LO + one aligned activity."

**If Incorrect (Option A or B):**
"Not quite. The learning objective asks learners to 'conduct' an interview, which is an application-level skill. Watching a video lecture (passive) or writing a reflection (analysis) doesn't give them practice actually conducting interviews. Effective microlessons match the activity type to the action verb in the LO. Look for the activity that gives hands-on practice."

---

### Challenge 3: Module Flow Design

**Challenge ID:** `scaffolding-3`  
**Title:** Module Flow Design  
**Difficulty:** 3  
**Concepts:** Module structure, scaffolding across microlessons  
**Badge:** Scaffold Master (earned after completing all 4 Scaffolding challenges)

**SCENARIO:**

You're organizing a module on "Python Data Analysis" that includes four microlessons. An AI assistant generated the content, but the sequence is illogical - it jumps around between foundational and advanced topics.

Current sequence:
1. Advanced Statistical Analysis with Pandas
2. Installing Python and Jupyter Notebook
3. Python Basic Syntax and Data Types
4. Introduction to Data Analysis Concepts

**QUESTION:**

Drag these microlessons into the correct order to create a logical module flow:

**ITEMS TO ARRANGE:**

- Introduction to Data Analysis Concepts
- Installing Python and Jupyter Notebook  
- Python Basic Syntax and Data Types
- Advanced Statistical Analysis with Pandas

**CORRECT ORDER:**

1. Introduction to Data Analysis Concepts (Context/Why)
2. Installing Python and Jupyter Notebook (Setup/Tools)
3. Python Basic Syntax and Data Types (Foundations)
4. Advanced Statistical Analysis with Pandas (Advanced Application)

**FEEDBACK:**

**If Correct:**
"Perfect module flow! You've created a logical progression: Context (why data analysis matters) → Setup (tools installation) → Foundations (basic syntax) → Advanced Application (statistical analysis). This sequence builds prerequisite knowledge step-by-step and prevents learners from hitting roadblocks. Each microlesson prepares them for the next."

**If Incorrect:**
"Not quite. Effective module sequencing follows a logic: Context/Introduction → Setup/Prerequisites → Foundational Skills → Advanced Application. Starting with advanced topics or installation before context confuses learners. Think about what knowledge or setup a learner needs before they can succeed at each step, then order accordingly."

---

### Challenge 4: Competency Mapping

**Challenge ID:** `scaffolding-4`  
**Title:** Competency Mapping  
**Difficulty:** 4  
**Concepts:** Competency structure, modules within competencies, modular thinking  
**Badge:** Scaffold Master (earned after completing all 4 Scaffolding challenges)

**SCENARIO:**

You're designing a new curriculum on "Product Management Fundamentals" for a corporate learning program. You have 9 microlessons that need to be organized into 3 modules under one competency.

**9 Microlessons:**
1. What is Product Management?
2. Writing User Stories
3. Prioritization Frameworks (RICE, MoSCoW)
4. Conducting User Research Interviews
5. Creating Product Roadmaps
6. Defining Product Vision and Strategy
7. Analyzing User Research Data
8. Sprint Planning Basics
9. Stakeholder Communication for Roadmaps

**QUESTION:**

Organize these 9 microlessons into 3 logical modules. Drag each microlesson into the appropriate module:

**Module 1: Product Strategy & Vision**
(Foundation - understanding the "what" and "why" of product management)

**Module 2: User Research & Discovery**  
(Gathering and analyzing user insights)

**Module 3: Roadmapping & Execution**
(Planning and communicating product direction)

**CORRECT GROUPINGS:**

**Module 1: Product Strategy & Vision**
- What is Product Management?
- Defining Product Vision and Strategy
- Sprint Planning Basics

**Module 2: User Research & Discovery**
- Conducting User Research Interviews
- Analyzing User Research Data
- Writing User Stories

**Module 3: Roadmapping & Execution**
- Prioritization Frameworks (RICE, MoSCoW)
- Creating Product Roadmaps
- Stakeholder Communication for Roadmaps

**FEEDBACK:**

**If Correct:**
"Excellent competency mapping! You've created three cohesive modules with clear thematic clustering. Module 1 establishes foundational PM concepts and strategy, Module 2 focuses on user research skills, and Module 3 covers roadmapping and prioritization. This structure allows for modular delivery - a client could take all three modules for comprehensive PM training, or select specific modules based on their team's needs. This is exactly how modular curriculum design enables flexibility and personalization."

**If Incorrect:**
"Not quite. Think about thematic coherence - which microlessons naturally belong together because they're teaching related skills or building toward a common capability? Module 1 should establish PM foundations and strategy, Module 2 should cluster user research skills, and Module 3 should focus on roadmapping and execution. Try grouping microlessons by shared theme rather than random distribution."

---

## PATH 4: ASSESSMENT QUALITY

### Challenge 1: Measurable vs Opinion-Based

**Challenge ID:** `assessment-1`  
**Title:** Measurable vs Opinion-Based  
**Difficulty:** 1  
**Concepts:** Measurable outcomes, assessment alignment to LOs  
**Badge:** Assessment Architect (earned after completing all 4 Assessment challenges)

**SCENARIO:**

You're reviewing an AI-generated quiz for a project management fundamentals course. One of the questions reads:

**Quiz Question:**
"Do you like agile project management methodologies?"
- Yes
- No  
- Sometimes

The learning objective for this section is: "Learners will be able to apply agile ceremonies (stand-ups, retrospectives, sprint planning) in a project context."

**QUESTION:**

What is the problem with this assessment question?

**OPTIONS:**

**A)** It measures personal preference/opinion rather than knowledge or skill application. It doesn't assess whether learners can actually apply agile ceremonies.

**B)** It should have more answer choices to be a valid multiple-choice question.

**C)** The grammar is incorrect and needs editing.

**CORRECT ANSWER:** A

**FEEDBACK:**

**If Correct (Option A):**
"Exactly right! This question measures opinion ('Do you like...?') rather than knowledge or skill. The learning objective requires learners to 'apply' agile ceremonies, so the assessment should ask them to demonstrate that application - for example, by describing when to use each ceremony or identifying which ceremony addresses a specific project need. Effective assessments must align with the action verb in the learning objective."

**If Incorrect (Option B or C):**
"Not quite. The issue isn't the number of answer choices or grammar - it's that this question measures personal preference rather than skill or knowledge. When the LO requires learners to 'apply' a concept, the assessment must measure application, not opinion. Look for assessments that ask learners to demonstrate the skill stated in the learning objective."

---

### Challenge 2: Exercise Clarity & Deliverables

**Challenge ID:** `assessment-2`  
**Title:** Exercise Clarity & Deliverables  
**Difficulty:** 2  
**Concepts:** Exercise design, clear deliverables, "don't make me think"  
**Badge:** Assessment Architect (earned after completing all 4 Assessment challenges)

**SCENARIO:**

You're QA-reviewing a colleague's course materials and find this exercise in a lesson on version control:

**Exercise: Git Practice**

"Practice using Git. Try different commands and see what happens. When you're done, move on to the next section."

You immediately recognize this violates the "don't make me think" principle - learners will waste cognitive load figuring out what to do instead of learning.

**QUESTION:**

Which revision provides the clarity, structure, and deliverables that learners need?

**OPTIONS:**

**A)** 
**Exercise: Git Practice**

Practice Git commands like commit, push, and pull. Experiment with branching if you have time. Submit your work when finished.

**B)** 
**Exercise: First Git Commit**

**Purpose:** Practice the basic Git workflow to track changes in a project.

**Time:** 15 minutes

**Steps:**
1. Initialize a new Git repository in a project folder (`git init`)
2. Create a new file called `README.md` and add one sentence describing your project
3. Stage your file (`git add README.md`)
4. Commit your changes with the message "Initial commit" (`git commit -m "Initial commit"`)
5. Verify your commit history (`git log`)

**Deliverable:** Screenshot of your terminal showing the successful commit and log output

**C)** 
**Exercise: Learn Git**

Use Git to manage a project. Follow best practices and create commits as needed.

**CORRECT ANSWER:** B

**FEEDBACK:**

**If Correct (Option B):**
"Perfect! This exercise follows all the best practices: clear purpose (why we're doing this), specific time estimate, step-by-step instructions, exact commands with syntax, and a concrete deliverable. Learners know exactly what to do and what success looks like. This prevents wasted cognitive load on logistics and lets them focus on learning the skill."

**If Incorrect (Option A or C):**
"Not quite. Effective exercises need: (1) clear purpose, (2) specific steps, (3) time estimate, (4) concrete deliverable. Vague instructions like 'practice Git' or 'follow best practices' force learners to guess what's expected. Good exercise design removes ambiguity so learners can focus their mental energy on learning, not logistics."

---

### Challenge 3: QA Rubric Application

**Challenge ID:** `assessment-3`  
**Title:** QA Rubric Application  
**Difficulty:** 3  
**Concepts:** QA criteria, learner perspective, alignment check  
**Badge:** Assessment Architect (earned after completing all 4 Assessment challenges)

**SCENARIO:**

You're conducting a QA review of a microlesson on "Creating Accessible Web Forms" using the standard QA rubric. The rubric checks for:
- Learning objective alignment
- Scaffolding/Bloom's progression  
- Clarity of instructions
- Accessibility of content itself
- Inclusive language

Here's the microlesson:

**Learning Objective:**
"Learners will be able to create accessible web forms using ARIA labels and semantic HTML."

**Content:**
The lesson provides a definition of ARIA labels and shows one code example of a labeled input field.

**Activity:**
"Build a complete registration form for a website. Include fields for name, email, password, and preferences. Make it accessible."

**QUESTION:**

Based on the QA rubric, which issues do you identify? (Select all that apply)

**OPTIONS (Multi-select):**

- [ ] No scaffolding - jumps from one example directly to building a complete form (missing guided practice)
- [ ] Activity instructions lack clarity - "make it accessible" is vague with no specific criteria
- [ ] No mention of how to test accessibility (learners don't know how to verify success)
- [ ] The learning objective and activity are misaligne